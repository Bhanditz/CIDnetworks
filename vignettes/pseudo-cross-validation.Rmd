My pseudo-cross-validation measure is like a Bayes Factor, but awesomer (and it might not be mine first)
=======================================================================

I thought this up while walking on Singapore's Siloso beach, then following it up with steak and beer at The Chop House. For science!

Consider the following procedure: we have a data set $Y_j, j \in \{1, ..., j\}$, a model $M$ with parameters $\theta$, and a prior distribution $p(\theta)$. For this case we must have that the $Y_j$ are independent conditional on $\theta$. We obtain a sample from the full posterior distribution, using your favorite sampling scheme -- say Markov Chain Monte Carlo, because that's how I usually do it -- and get a series of draws

$$
\theta_1, \theta_2, ... , \theta_n
$$

from the density $P_M(\theta | Y)$, indexed by $i$. Let these all be equally weighted draws, $W_i = 1$.

Now, suppose we split this data set into a pseudo in-sample $Y_{in}$ and out-sample $Y_{out}$ (even though we know we did the draws on the original full set). We can reweight these samples as if they were drawn from the in-sample set alone through importance weighting

$$
W^*_i = W_i \frac{P_M(\theta_i|Y_{in})}{P_M(\theta_i|Y_{in},Y_{out})} = W_i \frac{P_M(Y_{in}|\theta_i)p(\theta)}{P_M(Y_{in})} \frac{P_M(Y_{in},Y_{out})}{P_M(Y_{in},Y_{out}|\theta_i)p(\theta)}
$$

Cancelling and collecting, we have

$$
W^*_i = W_i \frac{P_M(Y_{in}|\theta_i)}{P_M(Y_{in},Y_{out}|\theta_i)} \frac{P_M(Y_{in})}{P_M(Y_{in},Y_{out})};
$$

given that conditional on $\theta$, $Y_{in}$ and $Y_{out}$ are independent, and collecting $C_M=\frac{P_M(Y_{in})}{P_M(Y_{in},Y_{out})}$, we now have

$$
W^*_i = W_i C_M \frac{P_M(Y_{in}|\theta_i)}{P_M(Y_{in}|\theta_i) P_M(Y_{out}|\theta_i)} = W_i C_M \frac{1}{ P_M(Y_{out}|\theta_i)}.
$$

Now, we have a weighted sample from the posterior distribution for our in-sample only.

What we really want to know is how well the out-sample data is predicted by this model and the in-sample data set, or $P_m(Y_{out}|Y_{in})$, which can be calculated by the marginalization

$$
P_m(Y_{out}|Y_{in}) = \int P_m(Y_{out}|Y_{in}, \theta) P_m(\theta | Y_{in}) d\theta = \int P_m(Y_{out}|\theta) P_m(\theta | Y_{in}) d\theta
$$

Given that our weighted draws from the posterior are being used, we have

$$
P_m(Y_{out}|Y_{in}) = \frac{\sum P_m(Y_{out}|\theta_i) W^*_i }{\sum W^*_i} 
= \frac{\sum P_m(Y_{out}|\theta_i) W_i C_M \frac{1}{ P_M(Y_{out}|\theta_i)} }{\sum W_i C_M \frac{1}{ P_M(Y_{out}|\theta_i)}}
$$

and lots of terms cancel; since $W_i=1$ we then have

$$
P_m(Y_{out}|Y_{in}) = \frac{\sum 1}{\sum \frac{1}{ P_M(Y_{out}|\theta_i)}} = \frac{n }{\sum \frac{1}{ P_M(Y_{out}|\theta_i)}}.
$$

Our measure for total model fit is then the improper marginal distribution over all. If we can partition the space into various out-of-sample pieces such that the union of $S_1, ..., S_K$ is the index $1, ..., n$, then we have our pseudo-cross-validation likelihood,

$$
Q_M(Y) = \prod_{k=1}^{K} \frac{n}{\sum_{i=1}^{n} \frac{1}{ P_M(Y_{S_k}|\theta_i)}}
$$

If we did one at a time $(S_i = \{i\})$, we'd have the simple leave-one-out case, calculated in far less time than proper LOO-CV measures, and has the virtue of being way easier to calculate logarithmically.

This Is Not A Bayes Factor
--------------------------

Recall the formula for estimating the marginal likelihood of a model from samples on the posterior is quite similar in appearance, but not in derivation: it's the harmonic mean of the full-data likelihood under those samples.

$$
\frac{1}{P_M(Y)} = \int \frac{1}{P_M(Y)} p(\theta) d\theta = \int \frac{1}{P_M(Y)} \frac{P_M(\theta|Y)P_M(Y)}{p_M(Y|\theta)} d\theta = \int \frac{P_M(\theta|Y)}{P_M(Y|\theta) }d\theta.
$$

This takes all the data at once, so the measure we get is instead

$$
P_M(Y) = \frac{1}{n} \sum_{i=1}^{n} \prod_{k=1}^{K} \frac{1}{P_M(Y_k|\theta_i)}
$$

switching the product/sum order.

Caveats
-------

I have no idea whether:

- this is more stable than the BF approach, but I can check this for a lot of cases I've got here. It's clearly far more specific, demanding conditional independence than BFs, but it falls right under the paradigm of cross-validation and out-of-sample measures, which I like.

- this has been done before. It seems so obvious to me which makes me think it has.




